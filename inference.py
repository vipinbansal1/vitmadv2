
from transformers import ViTFeatureExtractor
import SiameseNetwork
from PIL import Image
from transformers import ViTMAEForPreTraining
import torch

def data_preparation_for_similarity_evaluator(pixel_value, 
                                              noise, 
                                              image_generator):
    #Regenerate the image with masking as defined in "noise" criteria    
    regenerated_image = image_generator(pixel_value, noise = noise, output_hidden_states = True)
    
    #Latent Embedding vector
    latent_embedding = regenerated_image.hidden_states[12][:,1:,:]
   
    #Index of the grids that are considered for embedding
    embedded_grids_indices = torch.argsort(noise, dim=1)[:,:98] 
    
    #Reshaping image pixels into embedding format 
    reshaped_pixels = image_generator.patchify(pixel_value)
    
    indices = embedded_grids_indices[0].numpy()
    for i in range(len(indices)):
        index = indices[i]
        #Concatenation of actual image and the generated embeddings to highlight the relevant pixels
        reshaped_pixels[0,index,:] = (reshaped_pixels[0,index,:]+latent_embedding[0,i,:])/2
    
    #reshaped back to image dimensions
    embedded_pixel_values = image_generator.unpatchify(reshaped_pixels)    
    return embedded_pixel_values

def inference(pixel_values, 
              image_generator, 
              advance_similarity_evaluator):
    #Number of grids possible in 224*224 with 16*16 sample size without overlapping
    grid_count = 196
    
    #Functionality to control the randomness of the grids
    noise = torch.rand(1, grid_count) 
    
    #Re-geenrate the image
    outputs = image_generator(pixel_values, noise = noise)
    
    #To consider the masked grids for embeddings which have been generated by the image_generator
    noise = 1-noise
        
    embedded_pixel_values_original = data_preparation_for_similarity_evaluator(
                                                pixel_values, 
                                                noise, 
                                                image_generator)
    
    embedded_pixel_values_generated = data_preparation_for_similarity_evaluator(
                                                outputs, 
                                                noise, 
                                                image_generator)
    
    #Evaluate Similarity probability value
    score = advance_similarity_evaluator(embedded_pixel_values_original, 
                                         embedded_pixel_values_generated)
        
    return score
    
image = Image.open("test.jpg")

feature_extractor = ViTFeatureExtractor.from_pretrained("facebook/vit-mae-large")
pixel_values = feature_extractor(image, return_tensors="pt").pixel_values

image_generator = ViTMAEForPreTraining.from_pretrained("vit_mae_trained_model_path/")

advance_similarity_evaluator = SiameseNetwork()
advance_similarity_evaluator.load_state_dict(torch.load(
                                "similarity_model_path/", 
                                weights_only=True))

score = inference(pixel_values, image_generator, advance_similarity_evaluator)